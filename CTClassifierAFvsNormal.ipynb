{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"CTClassifierAFvsNormal.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN92MasgThqissY6zFIopa6"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9qQesTz2u2o","executionInfo":{"status":"ok","timestamp":1612438959296,"user_tz":-330,"elapsed":129876,"user":{"displayName":"Tejas Radhakrishnan","photoUrl":"","userId":"07230829238675586453"}},"outputId":"5e68376b-ea72-4189-c59b-ce4c78afa59a"},"source":["# Mount gdrive into colab\n","from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"zCYrWfOYTty-"},"source":["!cp /content/drive/My\\ Drive/Project\\ files/CTdata1.zip /content"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"N3WpEt2ET7SU"},"source":["!unzip -q /content/CTdata1.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ptCFs6Fzdiu5"},"source":[""]},{"cell_type":"code","metadata":{"id":"0illT3fQ_z0a","executionInfo":{"status":"ok","timestamp":1612438967108,"user_tz":-330,"elapsed":5331,"user":{"displayName":"Tejas Radhakrishnan","photoUrl":"","userId":"07230829238675586453"}}},"source":["# Import statements\n","import os\n","import csv\n","import sys\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from scipy.io import loadmat\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","from sklearn.preprocessing import Normalizer"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"kAGy8Y-KAEqJ","outputId":"263aa33d-ba4b-4d5e-fef5-304d2874182f"},"source":["# Check GPU availability, use if present\n","%matplotlib inline\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n","torch.backends.cudnn.benchmark = True\n","\n","print(use_cuda)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["True\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"6MLZeUfPUkw2","outputId":"38a8dfae-e370-4934-9b55-55cf6ca4ae94"},"source":["# Shuffle data and split into training and validation using holdout \n","\n","reference = pd.read_csv('CTdata1/reference_data1.csv')\n","reference = reference.dropna()\n","reference = reference[reference['0'] != 2.0]\n","shuffled = reference.sample(frac = 1.0)\n","\n","train_csv = shuffled[:-5200]\n","val_csv = shuffled[-500:]\n","test_csv = shuffled[-3500:]\n","\n","train_csv.to_csv('training_data1.csv')\n","val_csv.to_csv('validation_data1.csv')\n","test_csv.to_csv('test_data1.csv')\n","\n","print(reference)\n","\n","print(val_csv)\n","print(train_csv)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["       A00001_1    0\n","0      A00001_2  0.0\n","1      A00001_3  0.0\n","2      A00002_1  0.0\n","3      A00002_2  0.0\n","4      A00002_3  0.0\n","...         ...  ...\n","24595  A08527_2  0.0\n","24596  A08527_3  0.0\n","24597  A08528_1  0.0\n","24598  A08528_2  0.0\n","24599  A08528_3  0.0\n","\n","[17257 rows x 2 columns]\n","       A00001_1    0\n","11142  A03863_2  1.0\n","7650   A02649_1  1.0\n","13795  A04786_1  0.0\n","17922  A06207_3  0.0\n","9184   A03184_2  0.0\n","...         ...  ...\n","8652   A03000_2  0.0\n","20743  A07186_1  0.0\n","10461  A03626_3  0.0\n","4186   A01448_3  0.0\n","1426   A00492_3  0.0\n","\n","[500 rows x 2 columns]\n","       A00001_1    0\n","16878  A05853_1  0.0\n","4010   A01387_2  0.0\n","4939   A01710_1  0.0\n","21363  A07400_3  0.0\n","14593  A05071_3  0.0\n","...         ...  ...\n","1747   A00604_3  0.0\n","20493  A07095_2  0.0\n","23423  A08115_2  0.0\n","3622   A01254_2  0.0\n","9523   A03301_3  0.0\n","\n","[12057 rows x 2 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6La9_y8ASBt0","executionInfo":{"status":"ok","timestamp":1612438975238,"user_tz":-330,"elapsed":6441,"user":{"displayName":"Tejas Radhakrishnan","photoUrl":"","userId":"07230829238675586453"}}},"source":["!cp /content/drive/My\\ Drive/Project\\ files/*.csv /content/\r\n","train_csv = pd.read_csv('training_data1.csv')\r\n","val_csv = pd.read_csv('validation_data1.csv')\r\n","test_csv = pd.read_csv('test_data1.csv')"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fimdksq2jkW","executionInfo":{"status":"ok","timestamp":1612439170768,"user_tz":-330,"elapsed":802,"user":{"displayName":"Tejas Radhakrishnan","photoUrl":"","userId":"07230829238675586453"}},"outputId":"5ba415b6-42fe-4de7-9065-22e1c1f9b765"},"source":["count_0 = len(train_csv[train_csv['0'] == 1]) + len(val_csv[val_csv['0'] == 1]) + len(test_csv[test_csv['0'] == 1])\r\n","print(count_0)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["2180\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g__O_n9rRhMg"},"source":["!cp /content/*.csv /content/drive/My\\ Drive/Project\\ files/"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Ejq2cAeTAbzh"},"source":["class AFDataset(Dataset):\n","    \"\"\"Atrial Fibrillation Chirplet Transformed Dataset\"\"\"\n","    \n","    def __init__(self, csv_file, root_dir):\n","        \"\"\"\n","        Args:\n","            csv_file (string): Path to the csv file with labels.\n","            root_dir (string): Directory with all the signals\n","        \"\"\"\n","        \n","        self.reference = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        \n","    def __len__(self):\n","        return len(self.reference)\n","    \n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        \n","        ECG_name = os.path.join(self.root_dir, self.reference.iloc[idx, 1])\n","        ECG = loadmat(ECG_name)['res']\n","        ECG = (ECG - ECG.mean(keepdims = True)) / np.sqrt(ECG.var(keepdims = True))\n","        ECG = torch.FloatTensor(ECG)\n","        ECG = ECG.reshape(1, ECG.shape[0],ECG.shape[1])\n","        label = np.array(self.reference.iloc[idx, 2].astype(int))\n","        \n","        return torch.FloatTensor(ECG), label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"VLcB71vIAe7S","outputId":"52b8ee52-2099-4d0b-a664-355c67a64a51"},"source":["# Weights for sampler into network, fixes class imbalance\n","\n","weights_train = np.array(train_csv['0'])\n","weights_val = np.array(val_csv['0'])\n","\n","weight_normal_train = len(weights_train) / (float) (np.count_nonzero(weights_train == 0))\n","weight_af_train = len(weights_train) / (float) (np.count_nonzero(weights_train == 1))\n","\n","weight_normal_val = len(weights_val) / (float) (np.count_nonzero(weights_val == 0))\n","weight_af_val = len(weights_val) / (float) (np.count_nonzero(weights_val == 1))\n","\n","weights_train[weights_train == 0] = weight_normal_train\n","weights_train[weights_train == 1] = weight_af_train\n","\n","weights_val[weights_val == 0] = weight_normal_val\n","weights_val[weights_val == 1] = weight_af_val\n","\n","weights_train = torch.DoubleTensor(weights_train.astype('float32'))\n","weights_val = torch.DoubleTensor(weights_val.astype('float32'))\n","\n","train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights_train, len(weights_train))\n","val_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights_val, len(weights_val))\n","\n","print(weight_normal_train, weight_af_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1.1428436018957346 8.000663570006635\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"Z1_LIszn6RxD"},"source":["# Parameters for CUDA\n","params = {'batch_size': 32,\n","        'num_workers': 30}\n","\n","# Hyperparameters\n","MAX_EPOCHS = 60\n","ALPHA = 1e-5\n","REG = 0.01"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"JQEOpk75Ahz0"},"source":["# Generate training and validation datasets\n","train_set = AFDataset('training_data1.csv', 'CTdata1/')\n","train_generator = DataLoader(train_set, **params, sampler = train_sampler)\n","\n","val_set = AFDataset('validation_data1.csv', 'CTdata1/')\n","val_generator = DataLoader(val_set, **params, sampler = val_sampler)\n","\n","test_set = AFDataset('test_data1.csv', 'CTdata1/')\n","test_generator = DataLoader(test_set, **params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y11XAeQOvbDf"},"source":["plt.imshow(val_set[0][0][0])\r\n","print(val_set[0][0][0].shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"1Xp4tu_JAlVq"},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.bn4 = nn.BatchNorm2d(3)\n","        self.bn1 = nn.BatchNorm2d(5)\n","        self.bn2 = nn.BatchNorm2d(7)\n","        self.bn3 = nn.BatchNorm2d(9)\n","        self.conv4 = nn.Conv2d(1, 3, (30,512))\n","        self.conv1 = nn.Conv2d(3, 5, (20, 256))\n","        self.conv2 = nn.Conv2d(5, 7, (12, 128))\n","        self.conv3 = nn.Conv2d(7, 9, (8, 64))\n","        self.fc1 = nn.Linear(100 * 244 * 2, 500)\n","        self.fc2 = nn.Linear(500, 200)\n","        self.fc3 = nn.Linear(200, 3)\n","        self.do1 = nn.Dropout(p = 0.2)\n","        self.lstm_layer = nn.LSTM(input_size = 9 * 9, hidden_size = 100, num_layers = 1, batch_first = True, bidirectional = True)\n","\n","    def forward(self, x):\n","        x = self.do1(self.bn4(F.relu(self.conv4(x))))\n","        x = self.do1(self.bn1(F.relu(self.conv1(x))))\n","        x = self.do1(self.bn2(F.relu(self.conv2(x))))\n","        x = self.do1(self.bn3(F.relu(self.conv3(x))))\n","        x = x.reshape(-1, 244 , 9 * 9)\n","        x, _ = self.lstm_layer(x)\n","        x = x.reshape(-1, 244 * 100 * 2)\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = self.fc2(self.do1(x))\n","        x = self.fc3(self.do1(F.relu(x)))\n","        return x\n","\n","\n","net = Net()\n","net.to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(net.parameters(), lr=ALPHA, weight_decay = REG)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rcQMbIzxo2Ir"},"source":["net.load_state_dict(torch.load('/content/drive/My Drive/Project files/ctdata1classifier.pt'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"way_QJ7joocZ"},"source":["def adjust_learning_rate(optimizer, lrd, epoch, schedule):\r\n","  if epoch in schedule:\r\n","    for param_group in optimizer.param_groups:\r\n","      print('lr decay from {} to {}'.format(param_group['lr'], param_group['lr'] * lrd))\r\n","      param_group['lr'] *= lrd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dBrfWwzFAoAL"},"source":["print('Running...')\n","\n","train_acc = []\n","val_acc = []\n","\n","# Loop over epochs\n","running_loss = 0.0\n","for epoch in range(MAX_EPOCHS):\n","    adjust_learning_rate(optimizer, 0.7, epoch, [10, 20, 30, 40])\n","    # Training\n","    correct = 0\n","    total = 0\n","    #torch.save(net.state_dict(), '/content/drive/My Drive/Project files/ctdata1classifier.pt')\n","    for i, (local_batch, local_labels) in enumerate(train_generator, 0):\n","        # Transfer to GPU\n","        local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n","\n","        # Model computations\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(local_batch)\n","        loss = criterion(outputs, local_labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 100 == 99:    # print every 100 mini-batches\n","            print('[%d, %5d] loss: %.3f' %\n","                (epoch + 1, i + 1, running_loss / 100))\n","            running_loss = 0.0\n","        \n","        _, predicted = torch.max(outputs.data, 1)\n","        total += local_labels.size(0)\n","        correct += (predicted == local_labels).sum().item()\n","\n","    train_acc.append(correct / total)\n","    print(\"Train acc : %d %%\" % (100 * correct / total))\n","\n","    # Validation\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for local_batch, local_labels in val_generator:\n","          # Transfer to GPU\n","          local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n","\n","          # Model computations\n","          outputs = net(local_batch)\n","          _, predicted = torch.max(outputs.data, 1)\n","          total += local_labels.size(0)\n","          correct += (predicted == local_labels).sum().item()\n","        val_acc.append(correct / total)\n","        print(\"Val acc : %d %%\" % (100 * correct / total))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvxk17fKqx7y"},"source":["# Confusion matrix generation\n","\n","test_cm_gen = DataLoader(test_set, **params)\n","\n","cm_test = np.array([[0, 0], [0, 0]])\n","\n","with torch.set_grad_enabled(False):\n","  for local_batch, local_labels in test_cm_gen:\n","    # Transfer to GPU\n","    local_batch, local_labels = local_batch.to(device), local_labels.to(device)\n","\n","    # Model computations\n","    outputs = net(local_batch)\n","    _, predicted = torch.max(outputs.data, 1)\n","    for idx in range(len(local_batch)):\n","      x = local_labels[idx]\n","      y = predicted[idx]\n","      cm_test[x][y] += 1\n","\n","print('\\n \\n', cm_test)\n","\n","tn = cm_test[0][0]\n","fn = cm_test[1][0]\n","fp = cm_test[0][1]\n","tp = cm_test[1][1]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Du_5mMuFQDtV"},"source":["n = tn + tp + fn + fp\r\n","acc = (tn + tp) / n\r\n","f1 = 2 * tp / (2 * tp + fp + fn)\r\n","s = (tp + fn) / n\r\n","p = (tp + fp) / n\r\n","mcc = (tp / n - s * p) / math.sqrt(p * s * (1 - p) * (1 - s))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q5hIwDtfQOn7"},"source":["print(acc)\r\n","print(f1)\r\n","print(mcc)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rMpOk6nTmj63"},"source":["plt.plot(train_acc, label = 'Training Accuracy')\r\n","plt.plot(val_acc, label = 'Validation Accuracy')\r\n","plt.xlabel('Epochs')\r\n","plt.ylabel('Accuracy')\r\n","plt.legend()\r\n","plt.show()"],"execution_count":null,"outputs":[]}]}